{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee4ab44c-1e0d-4f9d-975c-8159829d5bad",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Use the twitter API to source tweets with a given set of hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a631f38-cc6c-4a47-8296-558896856586",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0981f5a5-6059-48e1-bf3e-bc6e9d3e58c7",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Instantiate the twitter API and get the country code for the UK\n",
    "\n",
    "- The user needs to have a developer account and add their own keys\n",
    "- The UK is actually the 3rd country in the list returned by `search_geo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a2ffd28-6e4d-4dc7-9c10-66adcbb5b1e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "Unauthorized",
     "evalue": "401 Unauthorized\n32 - Could not authenticate you",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnauthorized\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m auth \u001B[38;5;241m=\u001B[39m tweepy\u001B[38;5;241m.\u001B[39mOAuthHandler(CONSUMER_TOKEN, CONSUMER_SECRET)\n\u001B[1;32m      8\u001B[0m api \u001B[38;5;241m=\u001B[39m tweepy\u001B[38;5;241m.\u001B[39mAPI(auth)\n\u001B[0;32m---> 11\u001B[0m places \u001B[38;5;241m=\u001B[39m \u001B[43mapi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch_geo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mUnited Kingdom\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mgranularity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcountry\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m place_id \u001B[38;5;241m=\u001B[39m places[\u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39mid\n",
      "File \u001B[0;32m~/miniforge3/envs/networks/lib/python3.9/site-packages/tweepy/api.py:46\u001B[0m, in \u001B[0;36mpayload.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     44\u001B[0m kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpayload_list\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m payload_list\n\u001B[1;32m     45\u001B[0m kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpayload_type\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m payload_type\n\u001B[0;32m---> 46\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/networks/lib/python3.9/site-packages/tweepy/api.py:3886\u001B[0m, in \u001B[0;36mAPI.search_geo\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m   3820\u001B[0m \u001B[38;5;129m@payload\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mplace\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mlist\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   3821\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msearch_geo\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   3822\u001B[0m     \u001B[38;5;124;03m\"\"\"search_geo(*, lat, long, query, ip, granularity, max_results)\u001B[39;00m\n\u001B[1;32m   3823\u001B[0m \n\u001B[1;32m   3824\u001B[0m \u001B[38;5;124;03m    Search for places that can be attached to a Tweet via\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3884\u001B[0m \u001B[38;5;124;03m    https://developer.twitter.com/en/docs/twitter-api/v1/geo/places-near-location/api-reference/get-geo-search\u001B[39;00m\n\u001B[1;32m   3885\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3886\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3887\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgeo/search\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendpoint_parameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3888\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlat\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlong\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mquery\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mip\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgranularity\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_results\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[1;32m   3889\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m   3890\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/networks/lib/python3.9/site-packages/tweepy/api.py:257\u001B[0m, in \u001B[0;36mAPI.request\u001B[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001B[0m\n\u001B[1;32m    255\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m BadRequest(resp)\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m401\u001B[39m:\n\u001B[0;32m--> 257\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Unauthorized(resp)\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m403\u001B[39m:\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Forbidden(resp)\n",
      "\u001B[0;31mUnauthorized\u001B[0m: 401 Unauthorized\n32 - Could not authenticate you"
     ]
    }
   ],
   "source": [
    "MAX_TWEETS = 50\n",
    "\n",
    "bearer_token = \"xxxxxx\"\n",
    "CONSUMER_TOKEN = \"xxxxxx\"\n",
    "CONSUMER_SECRET = \"xxxxxx\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_TOKEN, CONSUMER_SECRET)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "\n",
    "places = api.search_geo(query=\"United Kingdom\",granularity=\"country\")\n",
    "place_id = places[2].id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd86fd2-d396-468d-b603-4ed2494113ae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Instantiate the BERT tokenizers and model\n",
    "\n",
    "- My jupyter lab crashes when I use the tokenizer\n",
    "- Will probably need a GPU for reasonable runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d07992-c04e-44ec-a635-f4313a316dd4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ea85b-c201-4da9-a5d7-a24e974ef012",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Build the query\n",
    "\n",
    "- Add desired hashtags to the `hashtags` list\n",
    "- Current form builds an `x OR y OR z` query, avoids retweets, and gets tweets from the UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df7159-5ebd-4b5e-b6d9-acfb5af37127",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hashtags = ['Skype']#'Teams', 'Zoom', \n",
    "\n",
    "n_hashtags = len(hashtags)\n",
    "hashtag_string = ''\n",
    "for hashtag_index, hashtag in enumerate(hashtags):\n",
    "    if hashtag_index == n_hashtags - 1:\n",
    "        \n",
    "        hashtag_string += f'#{hashtag} '\n",
    "    else:\n",
    "        hashtag_string += f'#{hashtag} OR '\n",
    "        \n",
    "        \n",
    "query = f'{hashtag_string}   place:{place_id} -filter:retweets'\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ac0e12-b8b7-44da-96e5-352fad2ccf62",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Use the tweepy cursor and `search_tweets` to retrieve some tweets\n",
    "\n",
    "- Builds a list of the raw text from tweets \n",
    "- ### not kosher for ethics - same cell is below with attempts to get sentiment on tweets without local storage of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ca525-4ca9-48e6-9d18-c282c54eac0a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search_tweets, q=query, count=500, tweet_mode='extended').items(MAX_TWEETS):#\n",
    "    text = tweet.full_text.split('http')[0]\n",
    "    tweets.append(text)\n",
    "    print(text)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b50f07b-2432-4e28-bcce-19d2c143b95c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweet_sentiments = []\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search_tweets, q=query, count=100, tweet_mode='extended').items(MAX_TWEETS):\n",
    "\n",
    "    text = tweet.full_text.split('http')[0]\n",
    "    try:\n",
    "        text_tokens = tokenizer.encode(text)\n",
    "        sentiment = model.predict(text_tokens)\n",
    "\n",
    "        tweet_sentiments.append(sentiment)\n",
    "        print(sentiment)\n",
    "        print('\\n')\n",
    "    except:\n",
    "        print(f\"Tweet failed: {text}\")\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}